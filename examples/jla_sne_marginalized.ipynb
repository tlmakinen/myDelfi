{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as interpolate\n",
    "import simulators.jla_supernovae.jla_simulator as jla\n",
    "import pydelfi.ndes as ndes\n",
    "import pydelfi.delfi as delfi\n",
    "import pydelfi.score as score\n",
    "import pydelfi.priors as priors\n",
    "import tensorflow as tf\n",
    "from scipy.linalg import block_diag\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the prior\n",
    "In this case, we need to set up priors over interesting and nuisance parameters. The nuisance parameter prior could be conditional on the interesting parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([0, -1.5])\n",
    "upper = np.array([0.6, 0])\n",
    "prior = priors.Uniform(lower, upper)\n",
    "\n",
    "eta_lower = np.array([-20, 0, 0, -0.5])\n",
    "eta_upper = np.array([-18, 1, 6, 0.5])\n",
    "eta_prior = priors.Uniform(eta_lower, eta_upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the simulator\n",
    "This must have the signature `simulator(parameters, seed, args, batch)` -> `np.array([batch, ndata])`\n",
    "\n",
    "Note: In this case since we are going to infer the nuisance parameter marginalized posterior directly, the simulator takes in interesting parameters only, and draws nuisance parameters from their prior _as part of the simulation process_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JLASimulator = jla.JLA_Model()\n",
    "\n",
    "def simulator(theta, seed, simulator_args, batch):\n",
    "    \n",
    "    eta_prior = simulator_args[0]\n",
    "    eta = eta_prior.draw()\n",
    "    \n",
    "    return JLASimulator.simulation(np.concatenate([theta, eta]), seed)\n",
    "\n",
    "simulator_args = [eta_prior]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the compressor\n",
    "This must have the signature `compressor(data, args)` -> `np.array([n_summaries])`\n",
    "In this case we are going to do _nuisance hardened_ Gaussian score compression $$\\bar{\\mathbf{t}}_\\theta = \\mathbf{t}_\\theta - \\mathbf{F}_{\\theta\\eta}\\mathbf{F}^{-1}_{\\eta\\eta}\\mathbf{t}_\\eta$$ where $$\\mathbf{t}_{(\\theta, \\eta)} = \\nabla_{(\\theta, \\eta)}^T\\boldsymbol\\mu_*\\mathbf{C}^{-1}(\\mathbf{d}-\\boldsymbol\\mu_*)$$\n",
    "We'll use the class `score.Gaussian`. For this we'll need some fiducial parameters, the mean its derivative at the fiducial parameters, the inverse covariance, and the inverse Fisher matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_fiducial = np.array([0.2, -0.75])\n",
    "eta_fiducial = np.array([-19.04, 0.125, 2.64, -0.05])\n",
    "\n",
    "mu = JLASimulator.apparent_magnitude(np.concatenate([theta_fiducial, eta_fiducial]))\n",
    "Cinv = JLASimulator.Cinv\n",
    "\n",
    "h = np.array(abs(np.concatenate([theta_fiducial, eta_fiducial])))*0.01\n",
    "dmudt = JLASimulator.dmudt(np.concatenate([theta_fiducial, eta_fiducial]), h)\n",
    "\n",
    "Compressor = score.Gaussian(len(JLASimulator.data), np.concatenate([theta_fiducial, eta_fiducial]), \n",
    "                            mu = mu, Cinv = Cinv, dmudt = dmudt)\n",
    "Compressor.compute_fisher()\n",
    "Finv = Compressor.Finv[0:2,0:2]\n",
    "\n",
    "nuisance_indices = np.arange(2,6)\n",
    "\n",
    "def compressor(d, compressor_args):\n",
    "    nuisances_indices = compressor_args[0]\n",
    "    return Compressor.projected_scoreMLE(d, nuisance_indices)\n",
    "compressor_args = [nuisance_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress the JLA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_data = compressor(JLASimulator.data, compressor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create endemble of NDEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDEs = [ndes.ConditionalMaskedAutoregressiveFlow(n_parameters=2, n_data=2, n_hiddens=[50,50], n_mades=5, act_fun=tf.tanh, index=0),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=1, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=1),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=2, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=2),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=3, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=3),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=4, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=4),\n",
    "        ndes.MixtureDensityNetwork(n_parameters=2, n_data=2, n_components=5, n_hidden=[30,30], activations=[tf.tanh, tf.tanh], index=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DELFI object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble = delfi.Delfi(compressed_data, prior, NDEs, Finv = Finv, theta_fiducial = theta_fiducial, \n",
    "                       param_limits = [lower, upper],\n",
    "                       param_names = ['\\Omega_m', 'w_0'], \n",
    "                       results_dir = \"simulators/jla_supernovae/results_marginal/\",\n",
    "                       input_normalization=\"fisher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher pre-training to initialize the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DelfiEnsemble.fisher_pretraining()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Neural Likeihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_initial = 100\n",
    "n_batch = 100\n",
    "n_populations = 11\n",
    "\n",
    "DelfiEnsemble.sequential_training(simulator, compressor, n_initial, n_batch, n_populations, patience=10, simulator_args=simulator_args, compressor_args=compressor_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
